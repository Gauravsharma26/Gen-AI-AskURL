# Gen-AI-AskURL
An end-to-end RAG pipeline built with Streamlit that scrapes text from any URL, chunks it, generates embeddings with Hugging Face, stores them in FAISS, and retrieves contextually relevant answers.


A Streamlit app that uses Retrieval-Augmented Generation (RAG) to analyze and answer questions about online news articles using Gemini (Google Generative AI) and FAISS vector search.

ğŸš€ Features

Fetches and extracts text from up to 3 article URLs

Splits content into semantic chunks

Generates embeddings using Hugging Face models

Stores them locally in a FAISS vector database

Answers questions using Gemini 2.5 Flash

Displays sources for transparency

ğŸ§  Tech Stack

Streamlit â€“ Frontend UI

LangChain â€“ RAG framework

FAISS â€“ Vector similarity search

Hugging Face / Gemini â€“ Embeddings & LLM

dotenv â€“ API key management

âš™ï¸ Setup Instructions

Clone repo
1) git clone https://github.com/yourusername/news-research-tool.git
cd news-research-tool

2) Install dependencies

3) pip install -r requirements.txt


4) Add environment variables
->Create a .env file:

GEMINI_API_KEY=your_google_genai_api_key


Run the app

streamlit run app.py

ğŸ§© How It Works

Enter up to 3 article URLs in the sidebar.

Click Process URLs â†’ builds FAISS index (saved as faiss_store.pkl).

Ask a question in the main section â†’ retrieves top chunks â†’ Gemini generates an answer.

Displays summarized answer + sources.

ğŸ“ Project Structure
.
â”œâ”€â”€ app.py               # Main Streamlit app
â”œâ”€â”€ faiss_store.pkl      # Saved FAISS vectorstore (auto-created)
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env
â””â”€â”€ README.md

ğŸ”‘ Notes

Requires a valid Gemini API key (Google Generative AI).

You can switch to GoogleGenerativeAIEmbeddings instead of Hugging Face if desired.

Use FAISS.save_local() for safer persistence instead of pickle.

ğŸ§‘â€ğŸ’» Author

Gaurav Sharma
AI Engineer | LLM Developer